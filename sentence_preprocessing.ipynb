{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# temporally tagging sentences with heideltime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "temporally tagged sentences for date selection by HeidelTime (https://github.com/HeidelTime/heideltime)\n",
    "\n",
    "dump into cPickle files: e.g. `bpoil_bbc.dated_sents`  \n",
    "each file contains `[[(pub_date_sent1, sent1), (ref_date1_sent1, sent1), (ref_date2_sent1, sent1)], [(pub_date_sent2, sent2)], ...]`\n",
    "\n",
    "for example,\n",
    "`[('2010-11-29', 'The well was permanently sealed on 19 September . \\n'), ('2010-09-19', 'The well was permanently sealed on 19 September . \\n')]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we used our python wrapper with JPype for heideltime and will public our repository on this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dump sentence corpus used by TILSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tilse.data import corpora\n",
    "import _pickle as cPickle\n",
    "\n",
    "# set path to tilse pre-processed dataset\n",
    "# refer to TILSE_reproduction.ipynb\n",
    "TILSE_PATH = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libya\n",
      "961   33974\n",
      "egypt\n",
      "964   33508\n",
      "yemen\n",
      "948   13938\n",
      "syria\n"
     ]
    }
   ],
   "source": [
    "# keywords are collected from TILSE\n",
    "# reference: https://github.com/smartschat/tilse/blob/f944d3d546a8ee27921887761f84bba81c03d561/configs/timeline17/asmds_dateref_timeline17.json\n",
    "keyword_mapping = {\n",
    "    \"bpoil\": [\"bp\", \"oil\", \"spill\"],\n",
    "    \"egypt\": [\"egypt\", \"egyptian\"],\n",
    "    \"finan\": [\"financial\", \"economic\", \"crisis\"],\n",
    "    \"h1n1\": [\"h1n1\", \"swine\", \"flu\"],\n",
    "    \"haiti\": [\"haiti\", \"quake\", \"earthquake\"],\n",
    "    \"iraq\": [\"iraq\", \"iraqi\"],\n",
    "    \"libya\": [\"libya\", \"libyan\"],\n",
    "    \"mj\": [\"michael\", \"jackson\"],\n",
    "    \"syria\": [\"syria\", \"syrian\"],\n",
    "    \"yemen\": [\"yemen\"]\n",
    "}\n",
    "\n",
    "topics = ['libya', 'egypt', 'yemen', 'syria']\n",
    "\n",
    "topic_dt_sents = {}\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "    corpus = pickle.load(open(f'{TILSE_PATH}/crisis/dumped_corpora/{topic}.corpus.obj', 'rb'))\n",
    "    filtered_corpus = corpus.filter_by_keywords_contained(keyword_mapping[topic])\n",
    "    dt_sents = {}\n",
    "    cnt = 0\n",
    "    for doc in filtered_corpus.docs:\n",
    "        for sent in doc.sentences:\n",
    "            dt = sent.date.strftime('%Y-%m-%d')\n",
    "            dt_sents.setdefault(dt, [])\n",
    "            dt_sents[dt].append(str(sent))\n",
    "            cnt += 1\n",
    "    print(len(dt_sents), ' ', cnt)\n",
    "    topic_dt_sents.setdefault(topic, dt_sents)\n",
    "cPickle.dump(topic_dt_sents, open('tilse_crisis.filtered_sents', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keywords are collected from TILSE\n",
    "# reference: https://github.com/smartschat/tilse/blob/f944d3d546a8ee27921887761f84bba81c03d561/configs/crisis/tlsconstraints_dateref_crisis.json\n",
    "keyword_mapping = {\n",
    "    \"bpoil\": [\"bp\", \"oil\", \"spill\"],\n",
    "    \"egypt\": [\"egypt\", \"egyptian\"],\n",
    "    \"finan\": [\"financial\", \"economic\", \"crisis\"],\n",
    "    \"h1n1\": [\"h1n1\", \"swine\", \"flu\"],\n",
    "    \"haiti\": [\"haiti\", \"quake\", \"earthquake\"],\n",
    "    \"iraq\": [\"iraq\", \"iraqi\"],\n",
    "    \"libya\": [\"libya\", \"libyan\"],\n",
    "    \"mj\": [\"michael\", \"jackson\"],\n",
    "    \"syria\": [\"syria\", \"syrian\"]\n",
    "}\n",
    "\n",
    "topic_dt_sents = {}\n",
    "for topic in keyword_mapping:\n",
    "    print(topic)\n",
    "    corpus = pickle.load(open(f'{TILSE_PATH}/timeline17/dumped_corpora/{topic}.corpus.obj', 'rb'))\n",
    "    filtered_corpus = corpus.filter_by_keywords_contained(keyword_mapping[topic])\n",
    "    dt_sents = {}\n",
    "    cnt = 0\n",
    "    for doc in filtered_corpus.docs:\n",
    "        for sent in doc.sentences:\n",
    "            dt = sent.date.strftime('%Y-%m-%d')\n",
    "            dt_sents.setdefault(dt, [])\n",
    "            dt_sents[dt].append(str(sent))\n",
    "            cnt += 1\n",
    "    print(len(dt_sents), ' ', cnt)\n",
    "    topic_dt_sents.setdefault(topic, dt_sents)\n",
    "cPickle.dump(topic_dt_sents, open('tilse_timeline17.filtered_sents', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
