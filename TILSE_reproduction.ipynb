{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## https://github.com/smartschat/tilse\n",
    "\n",
    "# we run pre-processing (including sentence tokenization and temporal tagging) first\n",
    "# reference: https://github.com/smartschat/tilse/blob/master/bin/get-and-preprocess-data\n",
    "\n",
    "# then we only measure computation time for summarization in this script for fair comparison.\n",
    "\n",
    "# set path to tilse pre-processed dataset\n",
    "# After running tilse pre-processing, we should get data folder like\n",
    "# crisis/\n",
    "#    raw/\n",
    "#    dumped_corpora/\n",
    "# timeline17/\n",
    "#    raw/\n",
    "#    dumped_corpora/\n",
    "TILSE_PATH = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import pprint\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import spacy\n",
    "import _pickle as cPickle\n",
    "from tilse.models.submodular import submodular, upper_bounds\n",
    "from tilse.models.chieu import chieu\n",
    "from tilse.data import timelines\n",
    "from tilse.evaluation import rouge\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class newSubmodular(submodular.Submodular):\n",
    "    \n",
    "    def _run_for_one(self, t, corpora, topic_to_preprocessed, reference_timelines):\n",
    "        corpus = corpora[t]\n",
    "\n",
    "        params = self.params\n",
    "\n",
    "        results_rouge = {}\n",
    "        results_date_selection = {}\n",
    "        returned_timelines = {}\n",
    "\n",
    "        for i, timeline in enumerate(reference_timelines[t].timelines):\n",
    "            timeline_properties = self.get_timeline_properties(timeline)\n",
    "            groundtruth = timelines.GroundTruth([timeline])\n",
    "\n",
    "            pred = self.predict(corpus, topic_to_preprocessed[t], timeline_properties, params)\n",
    "\n",
    "            returned_timelines[t + \"_\" + str(i)] = pred\n",
    "\n",
    "        return returned_timelines\n",
    "\n",
    "    def run(self, corpora, reference_timelines):\n",
    "        topics = sorted(list(corpora.keys()))\n",
    "        results_rouge = {}\n",
    "        results_date = {}\n",
    "        returned_timelines = {}\n",
    "\n",
    "        topic_to_preprocessed = {}\n",
    "        for t in topics:\n",
    "            topic_to_preprocessed[t] = self.preprocess(t, corpora[t])\n",
    "\n",
    "        for t in topics:\n",
    "            new_returned_timelines = self._run_for_one(t, corpora,\n",
    "                                                       topic_to_preprocessed,\n",
    "                                                       reference_timelines)\n",
    "            returned_timelines.update(new_returned_timelines)\n",
    "\n",
    "        return returned_timelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configures are obtained from TILSE repo\n",
    "# we have verfied the reproducibility of TILSE\n",
    "# reference: https://github.com/smartschat/tilse/tree/f944d3d546a8ee27921887761f84bba81c03d561/configs\n",
    "exps = [\n",
    "    ('timeline17', {\n",
    "                      \"name\": \"asmds_tempdiv_dateref_timeline17\",\n",
    "                      \"algorithm\": \"submodular\",\n",
    "                      \"restrict_topics_to\": None,\n",
    "                      \"assess_length\": \"average_length_in_sentences\",\n",
    "                      \"sentence_representation\": \"ChieuSentenceRepresentation\",\n",
    "                      \"keyword_mapping\": {\n",
    "                        \"bpoil\": [\"bp\", \"oil\", \"spill\"],\n",
    "                        \"egypt\": [\"egypt\", \"egyptian\"],\n",
    "                        \"finan\": [\"financial\", \"economic\", \"crisis\"],\n",
    "                        \"h1n1\": [\"h1n1\", \"swine\", \"flu\"],\n",
    "                        \"haiti\": [\"haiti\", \"quake\", \"earthquake\"],\n",
    "                        \"iraq\": [\"iraq\", \"iraqi\"],\n",
    "                        \"libya\": [\"libya\", \"libyan\"],\n",
    "                        \"mj\": [\"michael\", \"jackson\"],\n",
    "                        \"syria\": [\"syria\", \"syrian\"],\n",
    "                        \"yemen\": [\"yemen\"]\n",
    "                      },\n",
    "                      \"rouge_computation\": \"original\",\n",
    "                      \"properties\": {\n",
    "                        \"constraint\": \"is_valid_total_length\",\n",
    "                        \"semantic_cluster\": \"clusters_by_similarity\",\n",
    "                        \"date_cluster\": \"clusters_by_date\",\n",
    "                        \"coefficients\": [1, 0, 1, 1]\n",
    "                      }\n",
    "                    }),\n",
    "    ('timeline17', {\n",
    "                      \"name\": \"tlsconstraints_reweighting_dateref_timeline17\",\n",
    "                      \"algorithm\": \"submodular\",\n",
    "                      \"restrict_topics_to\": None,\n",
    "                      \"assess_length\": \"average_length_in_sentences\",\n",
    "                      \"sentence_representation\": \"DateWeightedChieuSentenceRepresentation\",\n",
    "                      \"keyword_mapping\": {\n",
    "                        \"bpoil\": [\"bp\", \"oil\", \"spill\"],\n",
    "                        \"egypt\": [\"egypt\", \"egyptian\"],\n",
    "                        \"finan\": [\"financial\", \"economic\", \"crisis\"],\n",
    "                        \"h1n1\": [\"h1n1\", \"swine\", \"flu\"],\n",
    "                        \"haiti\": [\"haiti\", \"quake\", \"earthquake\"],\n",
    "                        \"iraq\": [\"iraq\", \"iraqi\"],\n",
    "                        \"libya\": [\"libya\", \"libyan\"],\n",
    "                        \"mj\": [\"michael\", \"jackson\"],\n",
    "                        \"syria\": [\"syria\", \"syrian\"],\n",
    "                        \"yemen\": [\"yemen\"]\n",
    "                      },\n",
    "                      \"rouge_computation\": \"original\",\n",
    "                      \"properties\": {\n",
    "                        \"constraint\": \"is_valid_individual_constraints\",\n",
    "                        \"semantic_cluster\": \"clusters_by_similarity\",\n",
    "                        \"date_cluster\": \"clusters_by_date\",\n",
    "                        \"coefficients\": [1, 1, 0, 1]\n",
    "                      }\n",
    "                    }),\n",
    "    ('crisis', {\n",
    "                  \"name\": \"tlsconstraints_reweighting_dateref_crisis\",\n",
    "                  \"algorithm\": \"submodular\",\n",
    "                  \"restrict_topics_to\": None,\n",
    "                  \"assess_length\": \"average_length_in_sentences\",\n",
    "                  \"sentence_representation\": \"DateWeightedChieuSentenceRepresentation\",\n",
    "                  \"keyword_mapping\": {\n",
    "                    \"bpoil\": [\"bp\", \"oil\", \"spill\"],\n",
    "                    \"egypt\": [\"egypt\", \"egyptian\"],\n",
    "                    \"finan\": [\"financial\", \"economic\", \"crisis\"],\n",
    "                    \"h1n1\": [\"h1n1\", \"swine\", \"flu\"],\n",
    "                    \"haiti\": [\"haiti\", \"quake\", \"earthquake\"],\n",
    "                    \"iraq\": [\"iraq\", \"iraqi\"],\n",
    "                    \"libya\": [\"libya\", \"libyan\"],\n",
    "                    \"mj\": [\"michael\", \"jackson\"],\n",
    "                    \"syria\": [\"syria\", \"syrian\"],\n",
    "                    \"yemen\": [\"yemen\"]\n",
    "                  },\n",
    "                  \"rouge_computation\": \"original\",\n",
    "                  \"properties\": {\n",
    "                    \"constraint\": \"is_valid_individual_constraints\",\n",
    "                    \"semantic_cluster\": \"clusters_by_similarity\",\n",
    "                    \"date_cluster\": \"clusters_by_date\",\n",
    "                    \"coefficients\": [1, 1, 0, 1]\n",
    "                  }\n",
    "                }),\n",
    "    ('crisis', {\n",
    "                  \"name\": \"asmds_tempdiv_dateref_crisis\",\n",
    "                  \"algorithm\": \"submodular\",\n",
    "                  \"restrict_topics_to\": None,\n",
    "                  \"assess_length\": \"average_length_in_sentences\",\n",
    "                  \"sentence_representation\": \"ChieuSentenceRepresentation\",\n",
    "                  \"keyword_mapping\": {\n",
    "                    \"bpoil\": [\"bp\", \"oil\", \"spill\"],\n",
    "                    \"egypt\": [\"egypt\", \"egyptian\"],\n",
    "                    \"finan\": [\"financial\", \"economic\", \"crisis\"],\n",
    "                    \"h1n1\": [\"h1n1\", \"swine\", \"flu\"],\n",
    "                    \"haiti\": [\"haiti\", \"quake\", \"earthquake\"],\n",
    "                    \"iraq\": [\"iraq\", \"iraqi\"],\n",
    "                    \"libya\": [\"libya\", \"libyan\"],\n",
    "                    \"mj\": [\"michael\", \"jackson\"],\n",
    "                    \"syria\": [\"syria\", \"syrian\"],\n",
    "                    \"yemen\": [\"yemen\"]\n",
    "                  },\n",
    "                  \"rouge_computation\": \"original\",\n",
    "                  \"properties\": {\n",
    "                    \"constraint\": \"is_valid_total_length\",\n",
    "                    \"semantic_cluster\": \"clusters_by_similarity\",\n",
    "                    \"date_cluster\": \"clusters_by_date\",\n",
    "                    \"coefficients\": [1, 0, 1, 1]\n",
    "                  }\n",
    "                }),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_ti = {\n",
    "}\n",
    "for (exp_dataset, exp_config) in exps:\n",
    "    \n",
    "    if exp_config[\"name\"] in exp_ti:\n",
    "        continue\n",
    "    \n",
    "    news_corpora = {}\n",
    "    temp_reference_timelines = defaultdict(list)\n",
    "    \n",
    "    corpus = f\"{TILSE_PATH}/{exp_dataset}\"\n",
    "    raw_directory = corpus + \"/raw/\"\n",
    "    dumped_corpora_directrory = corpus + \"/dumped_corpora/\"\n",
    "    keyword_mapping = {\n",
    "        \"bpoil\": [\"bp\", \"oil\", \"spill\"],\n",
    "        \"egypt\": [\"egypt\", \"egyptian\"],\n",
    "        \"finan\": [\"financial\", \"economic\", \"crisis\"],\n",
    "        \"h1n1\": [\"h1n1\", \"swine\", \"flu\"],\n",
    "        \"haiti\": [\"haiti\", \"quake\", \"earthquake\"],\n",
    "        \"iraq\": [\"iraq\", \"iraqi\"],\n",
    "        \"libya\": [\"libya\", \"libyan\"],\n",
    "        \"mj\": [\"michael\", \"jackson\"],\n",
    "        \"syria\": [\"syria\", \"syrian\"],\n",
    "        \"yemen\": [\"yemen\"]\n",
    "    }\n",
    "    restrict_topics_to = None\n",
    "    reference_timelines = {}\n",
    "    \n",
    "    for topic in sorted(os.listdir(raw_directory)):\n",
    "        if restrict_topics_to is not None and topic not in restrict_topics_to:\n",
    "            continue\n",
    "        print(topic)\n",
    "\n",
    "        news_corpora[topic] = pickle.load(open(dumped_corpora_directrory + topic + \".corpus.obj\", \"rb\"))\n",
    "\n",
    "        if keyword_mapping is not None and keyword_mapping[topic] is not None:\n",
    "            news_corpora[topic] = news_corpora[topic].filter_by_keywords_contained(keyword_mapping[topic])\n",
    "\n",
    "        for filename in sorted(list(os.listdir(raw_directory + \"/\" + topic + \"/timelines/\"))):\n",
    "            full_path = raw_directory + \"/\" + topic + \"/timelines/\" + filename\n",
    "\n",
    "            temp_reference_timelines[topic].append(\n",
    "                timelines.Timeline.from_file(codecs.open(full_path, \"r\", \"utf-8\", \"replace\"))\n",
    "            )\n",
    "\n",
    "    for topic in temp_reference_timelines:\n",
    "        reference_timelines[topic] = timelines.GroundTruth(temp_reference_timelines[topic])\n",
    "    \n",
    "    algorithm = newSubmodular(exp_config, None)\n",
    "    \n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    returned_timelines = algorithm.run(news_corpora, reference_timelines)\n",
    "\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print('total sec: ', elapsed) #FIXME: note that TILSE uses the same preprocessing for multiple timelines\n",
    "                                  #       with the same topic, thus to measure runtime for each timeline, we\n",
    "                                  #       have to add the preprocessing time instead of apportioning it.\n",
    "                                  #       A easy fix: in newSubmodular.run, measuring preprocessing time and\n",
    "                                  #       generation time seperately.\n",
    "                                  #       will be updated soon.\n",
    "    \n",
    "    groundtruths = {}\n",
    "\n",
    "    for topic in reference_timelines:\n",
    "        for i, tl in enumerate(reference_timelines[topic].timelines):\n",
    "            groundtruths[topic + \"_\" + str(i)] = tl\n",
    "\n",
    "    cPickle.dump((returned_timelines, groundtruths), open(exp_config[\"name\"] + \".pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
